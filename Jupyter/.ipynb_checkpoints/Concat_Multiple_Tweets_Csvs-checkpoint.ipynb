{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Execute the cell below to import all packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System functionality\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import math as math\n",
    "import json\n",
    "import cv2\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat tweets csvs and export\n",
    "\n",
    "Use only ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tweets_joh =r'/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_joh'\n",
    "path_tweets_lon =r'/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_lon'\n",
    "path_tweets_nyc =r'/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_nyc'\n",
    "path_tweets_ran =r'/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_ran'\n",
    "\n",
    "all_tweet_files_joh = glob.glob(path_tweets_joh + \"/*.csv\")\n",
    "all_tweet_files_lon = glob.glob(path_tweets_lon + \"/*.csv\")\n",
    "all_tweet_files_nyc = glob.glob(path_tweets_nyc + \"/*.csv\")\n",
    "all_tweet_files_ran = glob.glob(path_tweets_ran + \"/*.csv\")\n",
    "\n",
    "tweets_joh_frame = pd.DataFrame()\n",
    "tweets_lon_frame = pd.DataFrame()\n",
    "tweets_nyc_frame = pd.DataFrame()\n",
    "tweets_ran_frame = pd.DataFrame()\n",
    "\n",
    "list_joh_ = []\n",
    "list_lon_ = []\n",
    "list_nyc_ = []\n",
    "list_ran_ = []\n",
    "\n",
    "for file_ in all_tweet_files_joh:\n",
    "    df1 = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_joh_.append(df1)\n",
    "tweets_joh_frame = pd.concat(list_joh_)\n",
    "\n",
    "for file_ in all_tweet_files_lon:\n",
    "    df2 = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_lon_.append(df2)\n",
    "tweets_lon_frame = pd.concat(list_lon_)\n",
    "\n",
    "for file_ in all_tweet_files_nyc:\n",
    "    df3 = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_nyc_.append(df3)\n",
    "tweets_nyc_frame = pd.concat(list_nyc_)\n",
    "\n",
    "for file_ in all_tweet_files_ran:\n",
    "    try:\n",
    "        df4 = pd.read_csv(file_,index_col=None, header=0)\n",
    "        list_ran_.append(df4)\n",
    "    except:\n",
    "        pass\n",
    "tweets_ran_frame = pd.concat(list_ran_)\n",
    "\n",
    "tweets_joh_frame.to_csv(\"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_joh_all.csv\", encoding='utf-8', index=False)\n",
    "tweets_lon_frame.to_csv(\"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_lon_all.csv\", encoding='utf-8', index=False)\n",
    "tweets_nyc_frame.to_csv(\"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_nyc_all.csv\", encoding='utf-8', index=False)\n",
    "tweets_ran_frame.to_csv(\"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_ran_all.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize tweet frames\n",
    "\n",
    "Shape for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631549, 11)(2308977, 11)(2524608, 11)(11326306, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"{}{}{}{}\".format(tweets_joh_frame.shape,\n",
    "tweets_lon_frame.shape,\n",
    "tweets_nyc_frame.shape,\n",
    "tweets_ran_frame.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joh, Lon, Nyc, Ran into one csv and export\n",
    "\n",
    "Use only ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_everywhere_frame = pd.DataFrame()\n",
    "\n",
    "tweets_everywhere_files = [\"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_joh_all.csv\",\n",
    "                           \"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_lon_all.csv\",\n",
    "                           \"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_nyc_all.csv\",\n",
    "                           \"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_ran_all.csv\"]\n",
    "\n",
    "tweets_everywhere_df_list_ =[]\n",
    "\n",
    "for file_ in tweets_everywhere_files:\n",
    "    try:\n",
    "        df5 = pd.read_csv(file_,index_col=None, header=0)\n",
    "        tweets_everywhere_df_list_.append(df5)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tweets_everywhere_frame = pd.concat[tweets_everywhere_df_list_]\n",
    "tweets_everywhere_frame.to_csv(\"/home/stelios/Desktop/Honours Project/Samples/tweet_data/tweets_everywhere_all.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load user data\n",
    "\n",
    "Load users from Johannesburg, New York, London or Random into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_users_joh ='/home/stelios/Desktop/Honours Project/Samples/user_data/joh.csv'\n",
    "path_users_lon ='/home/stelios/Desktop/Honours Project/Samples/user_data/lon.csv'\n",
    "path_users_nyc ='/home/stelios/Desktop/Honours Project/Samples/user_data/nyc.csv'\n",
    "path_users_ran ='/home/stelios/Desktop/Honours Project/Samples/user_data/ran.csv'\n",
    "\n",
    "users_joh_frame = pd.read_csv(path_users_joh,index_col=None, header=0)\n",
    "users_lon_frame = pd.read_csv(path_users_lon,index_col=None, header=0)\n",
    "users_nyc_frame = pd.read_csv(path_users_nyc,index_col=None, header=0)\n",
    "users_ran_frame = pd.read_csv(path_users_ran,index_col=None, header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize user frames\n",
    "\n",
    "Shape for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28)(10000, 28)(10000, 28)(10000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"{}{}{}{}\".format(users_joh_frame.shape,\n",
    "users_lon_frame.shape,\n",
    "users_nyc_frame.shape,\n",
    "users_ran_frame.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat datframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = pd.concat([tweets_joh_frame,tweets_lon_frame,tweets_nyc_frame,tweets_ran_frame])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
